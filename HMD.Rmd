---
title: "Quality prediction for the manufacturing of the blood glucose strips"
output:
  html_document:
    keep_md: true
---
> Outline

1. Abstract 
2. IPQC data analysis (Part 1)
    + 2.1 Knowing the data
        - 2.1.1 Original data
        - 2.2.2 Data after preprocessing
    + 2.2 Analysis 
        - 2.2.1 SMOTE + Decision Tree
        - 2.2.2 SMOTE + Random Forest
        - 2.2.3 ROSE + Decision Tree
        - 2.2.4 ROSE + Random Forest
    + 2.3 Compare ROC curve
3. IPQC + FQC data analysis (Part 2)
    + 3.1 Filter variables directly by standard deviation
        - 3.1.1 Clustering without PCA
        - 3.1.2 PCA + Clustering
    + 3.2 Fiter variables by standard deviation after grouping dimensions
        - 3.2.1 Clustering without PCA
        - 3.2.2 PCA + Clustering

# 1. Abstract
Machine learning models to predict the quality of manufacturing of blood glucose test strips are presented in this study. A variety of models are built by inspection data from an anonymous manufacturer in Taiwan. The aim of this study is to predict the quality of the strips in advance and to reduce the cost of defective products before shipment.
The proposed approach is divided into two parts. In-Process Quality Control (IPQC) data are examined in the first part. Since the data of defective products are relatively rare, we should make the data more balanced before building a model. Synthetic Minority Over-Sampling Technique (SMOTE) and Random Over-sampling Example (ROSE) are used to balance the data, and subsequently classification models are developed by the decision tree and random forest. Evaluation results from Receiver Operating Characteristic Curve (ROC) show that the decision tree and random forest after SMOTE have better performance than the counterpart of ROSE model.
After exploring the IPQC data, the second part of this study combines different inspection results of blood glucose test strips under same batch of raw materials. Standard deviation filtering and Principal Component Analysis (PCA) are used to select or extract appropriate features before building the models. Different clusterings from K-means, hierarchical, and K-medoids methods are employed to facilitate the understanding on quality grading for blood glucose test strips. Different clusterings are externally validated against original category labels. Results show that performance of more than three groups degrades significantly regardless of the cluster methods.

#### The process of this study as below.  

```{r,warning = FALSE}
knitr::include_graphics("C:/Users/Christine Liou/Documents/Quality-prediction-for-the-manufacturing-of-the-blood-glucose-strips/Analysis process.jpg")

```

# 2. IPQC data analysis (Part 1)
## 2.1 Knowing the data
### 2.1.1 Original data
The below data is original excel inputting from the company. It is quiet massy, so we need to extract, transform and reorganized. 
```{r,warning = FALSE}
library(xlsx)
IPQC_2233_GCS <- read.xlsx("~/HMD/data-20180426/IPQC/C4H82233-IPQC.xls",encoding="UTF-8",startRow =10,endRow = 23,sheetIndex = 1 )
IPQC_2233_GCS
```


```{r,warning = FALSE}
library(reshape2)
IPQC_2233_GCS <- IPQC_2233_GCS[,1:9]
lookup <- IPQC_2233_GCS[1:3,]
lookup <- sapply(lookup,as.character)
lookup <- rbind(colnames(lookup),lookup)
colnames(lookup) <- NULL
lookup <- t(lookup)
lookup <- as.data.frame(lookup)
colnames(lookup) <- c("Level", "GCS","Row","Meter")
lookup <- lookup [-1,]
lapply(lookup, table, useNA = "ifany")
lookup$Level <- factor(lookup$Level)
lookup$Meter <- factor(lookup$Meter)
lookup$Row <- factor(lookup$Row)

IPQC_2233_GCS <- IPQC_2233_GCS[-(1:3),]
colnames(IPQC_2233_GCS)[1] <- "obs"

lIPQC_2233_GCS <- melt(IPQC_2233_GCS,id.vars = "obs", measure.vars = colnames(IPQC_2233_GCS)[-1],variable.name = "Level",value.name = "bg")
lIPQC_2233_GCS <- merge(lookup,lIPQC_2233_GCS,by="Level")
lIPQC_2233_GCS$Level <- ifelse(lIPQC_2233_GCS$Level == "Level.1" | lIPQC_2233_GCS$Level == "Level.1.1" | lIPQC_2233_GCS$Level == "Level.1.2"| lIPQC_2233_GCS$Level == "Level.1.3", "I", ifelse(lIPQC_2233_GCS$Level == "Level.2" | lIPQC_2233_GCS$Level == "Level.2.1" | lIPQC_2233_GCS$Level == "Level.2.2"| lIPQC_2233_GCS$Level =="Level.2.3", "II", lIPQC_2233_GCS$Level))
lIPQC_2233_GCS$bg <- as.numeric(lIPQC_2233_GCS$bg)
lIPQC_2233_GCS$Row <- as.character(lIPQC_2233_GCS$Row)

lIPQC_2233_GCS$ave_bg <- ave(lIPQC_2233_GCS$bg, list(lIPQC_2233_GCS$Row,lIPQC_2233_GCS$Level), FUN = function(x) mean(x, na.rm = TRUE))
lIPQC_2233_GCS$ave_rdiff <- lIPQC_2233_GCS$bg - lIPQC_2233_GCS$ave_bg
lIPQC_2233_GCS$ave_rdiffpc <- (lIPQC_2233_GCS$ave_rdiff/lIPQC_2233_GCS$ave_bg)*100
head(lIPQC_2233_GCS)

```

### 2.1.2 Data after preprocessing
After cleaning, transforming, and calculating, the whole IPQC data is combined. The first column marks the strips pass or not. The two to seven columns are the strip's tags, shows us the pass level, the batch name, the blood sugar rate levels, the row, the estimated meter, and the observed number. The "bg" column is the strip tested outcome. We use the same real blood to test the strip. Therefore, based on the same testing blood, the outcome of the strip should nearly the same. If the "bg" quite different from other strips, that means the strip might be bad quality. 

```{r,warning = FALSE}
load("~/HMD/RDATA/IPQC_all.RData")
head(IPQC)
```

After removing the outlier based on boxplot, the strips with the same Row and obs are drawn a boxplot according to the 'ave_rdiffpc'(averaged of the row difference percentage). As we can see, the boxplots of the pass have more similar average and IQR than NG.
```{r,warning = FALSE}
library(dplyr)
IPQC_PASS <- filter(IPQC, IPQC$passornot=="pass")
IPQC_NG <- filter(IPQC, IPQC$passornot=="NG")
a <- which(IPQC_PASS$ave_rdiffpc %in% boxplot.stats(IPQC_PASS$ave_rdiffpc)$out) #removed the outlier
IPQC_PASS <- IPQC_PASS[-a,]
IPQC <- rbind(IPQC_PASS,IPQC_NG)

library(ggplot2)
p_naout <- ggplot(IPQC, aes(x=obs, y=ave_rdiffpc))+ geom_boxplot() + theme(axis.text.x = element_text(angle = 45))+ facet_grid(Row ~passornot)+ scale_x_discrete(limits= c("1(左吸)","2(左吸)","3(左吸)","4(左吸)","5(左吸)","6(右吸)","7(右吸)","8(右吸)","9(右吸)","10(右吸)")) 
p_naout+ ggtitle("Boxplot IPQC before balance_remove pass outlier")
```

The difference between pass and NG might have two reasons. First, the variance of the data should be small result in the pass strips. In other words, because ave_rdiffpc of the strips are quite diverse, the strips are not passed. Therefore, the boxplot in the NG part has different shapes. The other reason might be the number of data. With fewer collected data, the boxplot of NG would be quiet different. 
According to the codes below, we have 3993 pass data and only 160 NG data. 
```{r,warning = FALSE}
library(DMwR)
set.seed(1111)
table(IPQC$passornot)
```

## 2.2 Analysis
### 2.2.1 SMOTE + Decision Tree
Our data is imbalanced data. Applying machine learning model with imbalance data often causes the model to develop a bias towards the majority class. Therefore, we should balance the data first and then build the classification model. SMOTE is based on nearest neighbors judged by Euclidean Distance between data points in feature space. It selects examples that are close in the feature space, drawing a line between the examples in the feature space and drawing a new sample at a point along that line.
```{r,warning = FALSE}
IPQC_SMOTE <- SMOTE(passornot ~ ., IPQC, perc.over = 1150,perc.under=150)
table(IPQC_SMOTE$passornot)
```

After SMOTE, as we can see the  NG boxplot at the right side has better performance. The boxplots look quite similar. 
```{r,warning = FALSE}
smote <- ggplot(IPQC_SMOTE, aes(x=obs, y=ave_rdiffpc))+ geom_boxplot() + theme(axis.text.x = element_text(angle = 45))+ facet_grid(Row ~passornot)+ scale_x_discrete(limits= c("1(左吸)","2(左吸)","3(左吸)","4(左吸)","5(左吸)","6(右吸)","7(右吸)","8(右吸)","9(右吸)","10(右吸)")) 
smote + ggtitle("Boxplot IPQC after SMOTE")
```

Separate the data into training set and testing set.
```{r,warning = FALSE}

### 資料切分
np <- ceiling(0.1*nrow(IPQC_SMOTE))
test <- sample(1:nrow(IPQC_SMOTE),np)
IPQC_test <- IPQC_SMOTE[test,]
IPQC_train <- IPQC_SMOTE[-test,]

table(IPQC_train$passornot)/nrow(IPQC_train)
table(IPQC_test$passornot)/nrow(IPQC_test)
```

Build the decision tree by rpart. 
```{r,warning = FALSE}
library(rpart)
IPQC_tree <- rpart(passornot ~   Row+obs + ave_rdiffpc, 
                   data = IPQC_train,
                   method = "class")  
IPQC_tree
```

Pruning
```{r,warning = FALSE}
### 剪枝
printcp(IPQC_tree)
plotcp(IPQC_tree)

#取最小錯誤率剪枝
prunetree_IPQC <- prune(IPQC_tree, cp = IPQC_tree$cptable[which.min(IPQC_tree$cptable[,"xerror"]),"CP"])

#取最小錯誤率加上一倍標準誤
opt <- which.min(IPQC_tree$cptable[,"xerror"])
oneSe <- which(IPQC_tree$cptable[, "rel error"] < 
                IPQC_tree$cptable[opt,"xerror"] + IPQC_tree$cptable[opt, "xstd"])[1]

cpOneSe <- IPQC_tree$cptable[oneSe, "CP"]
IPQC_pruneOneSe <- prune(IPQC_tree, cp = cpOneSe)

knitr::kable(
  IPQC_tree$cptable, caption = ' 分類樹複雜度參數表',
  booktabs = TRUE
)

```

Visualize the result of the tree.
```{r,warning = FALSE}
### 畫圖
library(rpart.plot)
#opar<-par(no.readonly = T)
#par(mfrow=c(1,2))
rpart.plot(IPQC_tree, digits = 3, cex=0.8, sub="剪枝前")
rpart.plot(prunetree_IPQC, digits = 3, cex=0.8, sub="剪枝後")
rpart.plot(IPQC_pruneOneSe, digits = 3, cex=0.8, sub="onese剪枝後")
#剪枝前後差不多，因為cp最小取0.01，而原本rpart預設值就是0.01所以沒啥差
```

Calculate the accuracy and sensitivity of training set.
```{r,warning = FALSE}
#訓練集
passornot_train <- IPQC_SMOTE$passornot[-test]
train_prob <- predict(IPQC_tree,IPQC_train, type = "prob")
train_label <- predict(IPQC_tree,IPQC_train, type = "class")

table_train <- table(passornot_train,train_label)
correct_train <- sum(diag(table_train))/sum(table_train)*100
correct_train #69.56699

sensitivity <- table_train[2,2]/sum(table_train[2,])*100
sensitivity # 69.99227
```

Calculate the accuracy and sensitivity of testing set. 
```{r,warning = FALSE}
#測試集
passornot_test <- IPQC_SMOTE$passornot[test]
test_prob <- predict(IPQC_tree,IPQC_test, type = "prob")
test_label <- predict(IPQC_tree,IPQC_test, type = "class")
table_test <- table(passornot_test,test_label)
# data.frame(test_prob, test_label)
correct_test <- sum(diag(table_test))/sum(table_test)*100
correct_test #訓練集資料正確率 63.23529 %  

sensitivity <- table_test[2,2]/sum(table_test[2,])*100
sensitivity #測試集的sensitivity 65.98639%
```

Draw the ROC curve.
```{r,warning = FALSE}
### ROC curve
library(pROC)
levels(IPQC_test$passornot)
head(IPQC_test$passornot)
str(IPQC_test$passornot) # "pass": 1, "NG":2

modelroc_Stree <- roc(IPQC_test$passornot,test_prob[,"NG"]) # "pass": 1, "NG":2

plot(modelroc_Stree, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE, auc.polygon.col="skyblue", print.thres=TRUE)
```

```{r,warning = FALSE}
library(pROC)
modelroc_Stree <- roc(IPQC_test$passornot,test_prob[,"NG"]) # "pass": 1, "NG":2
```

### 2.2.2 SMOTE + Random Forest
Build the random forest model. 
```{r,warning = FALSE}
### 建隨機森林
library(randomForest)
#set.seed(1117)
rf <- randomForest(passornot ~ Row + obs + ave_rdiffpc, data = IPQC_train, ntree = 100)
rf

plot(rf)
```

```{r,warning = FALSE}
### 變數重要性
importance(rf) 
varImpPlot(rf)
```

Tuning the mtry 
```{r,warning = FALSE}
### CV調mtry
library(caret)
#set.seed(100)
mtryGrid <- data.frame(mtry = floor(seq(1, ncol(IPQC_train), length = 10)))
rfTune <- train(passornot ~ Row + obs + ave_rdiffpc, 
                data = IPQC_train,
                method = "rf",
                tuneGrid = mtryGrid,
                ntree = 100,
                importance = TRUE,
                trControl = trainControl(method = "cv",number = 10))
rfTune
plot(rfTune)
```

Calculate the accuracy and sensitivity of testing set.
```{r,warning = FALSE}

passornot_test <- IPQC_SMOTE$passornot[test]
test_prob <- predict(rfTune,IPQC_test, type = "prob")
test_label <- predict(rfTune,IPQC_test, type = "raw")
table_test <- table(passornot_test,test_label)

correct_test <- sum(diag(table_test))/sum(table_test)*100
correct_test #測試集資料正確率 69.48529 %  

sensitivity <- table_test[2,2]/sum(table_test[2,])*100
sensitivity #測試集的sensitivity 75.1634%
```


Plot the ROC curve. 
```{r,warning = FALSE}
### ROC
library(pROC)
modelroc_Srf <- roc(IPQC_test$passornot,test_prob[,"NG"]) # "pass": 1, "NG":2

plot(modelroc_Srf, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE, auc.polygon.col="skyblue", print.thres=TRUE)
```


### 2.2.3 ROSE + Decision Tree
In addition to using SMOTE to balance the data, I also use another method provided in R called ROSE(Random Over-sampling Example). After ROSE, the pass data and NG data have samilar number of data.
```{r,warning = FALSE}
library(ROSE)
set.seed(111)
IPQC_ROSE <- ROSE(passornot~., data=IPQC,N=nrow(IPQC), p=0.5, seed=1, hmult.majo = 0.25, hmult.mino = 0.5)$data            
#ROSE函數包的人工合成數據(ROSE)、過採樣、欠採樣及融合過採樣和欠採樣，根據Nicola文章，ROSE的ROCcurve 表現優於其他三者，所以採用ROSE套件中的ROSE函數進行數據平衡

table(IPQC_ROSE$passornot)

```

The boxplot after ROSE as below. 
```{r,warning = FALSE}
rose <- ggplot(IPQC_ROSE, aes(x=obs, y=ave_rdiffpc))+ geom_boxplot() + theme(axis.text.x = element_text(angle = 45))+ facet_grid(Row ~passornot)+ scale_x_discrete(limits= c("1(左吸)","2(左吸)","3(左吸)","4(左吸)","5(左吸)","6(右吸)","7(右吸)","8(右吸)","9(右吸)","10(右吸)")) 
rose+ ggtitle("Boxplot IPQC after ROSE")
```

Saperate the data into training and testing set. 
```{r,warning = FALSE}
### 資料切分
np <- ceiling(0.1*nrow(IPQC_ROSE))
test <- sample(1:nrow(IPQC_ROSE),np)
IPQC_test <- IPQC_ROSE[test,]
IPQC_train <- IPQC_ROSE[-test,]

```


Build the decision tree. 
```{r,warning = FALSE}
### 建樹
library(rpart)
IPQC_tree <- rpart(passornot ~   Row + obs + ave_rdiffpc, method = "class", data = IPQC_train, control = rpart.control(minbucket = 200)) 

### 剪枝
printcp(IPQC_tree)
plotcp(IPQC_tree)
prunetree_IPQC <- prune(IPQC_tree, cp = IPQC_tree$cptable[which.min(IPQC_tree$cptable[,"xerror"]),"CP"])


### 畫圖
library(rpart.plot)
#opar<-par(no.readonly = T)
#par(mfrow=c(1,2))
rpart.plot(IPQC_tree, digits = 3, cex=0.8, sub="剪枝前")
rpart.plot(prunetree_IPQC, digits = 3, cex=0.8)
#剪枝前後一樣

rpart.rules(x = IPQC_tree,cover = TRUE)
```

Calculate the accuracy and sensitivity of training set.

```{r,warning = FALSE}
### 模型評估
#訓練集
passornot_train <- IPQC_ROSE$passornot[-test]
train_prob <- predict(IPQC_tree,IPQC_train, type = "prob")
train_label <- predict(IPQC_tree,IPQC_train, type = "class")

table_train <- table(passornot_train,train_label)
correct_train <- sum(diag(table_train))/sum(table_train)*100
correct_train #69.56699

sensitivity <- table_train[2,2]/sum(table_train[2,])*100
sensitivity # 69.99227
```

Calculate the accuracy and sensitivity of training set.
```{r,warning = FALSE}
#測試集的正確率
passornot_test <- IPQC_ROSE$passornot[test]
test_prob <- predict(IPQC_tree,IPQC_test, type = "prob")
test_label <- predict(IPQC_tree,IPQC_test, type = "class")
table_test <- table(passornot_test,test_label)
# data.frame(test_prob, test_label)

correct_test <- sum(diag(table_test))/sum(table_test)*100
correct_test #測試集資料正確率 71.2963 %  

sensitivity <- table_test[2,2]/sum(table_test[2,])*100
sensitivity #測試集的sensitivity 15.38462 %
```


Draw the ROC curve.
```{r,warning = FALSE}
# ROC
library(pROC)
modelroc_Rtree <- roc(IPQC_test$passornot,test_prob[,"NG"]) # "pass": 1, "NG":2

plot(modelroc_Rtree, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE, auc.polygon.col="skyblue", print.thres=TRUE)
```

### 2.2.4 ROSE + Random Forest
Build the random forest model.
```{r,warning = FALSE}
#建森林
library(randomForest)
#set.seed(111)
rf <- randomForest(passornot ~ Row + obs + ave_rdiffpc, data = IPQC_train, ntree = 100)
rf_predict <- predict(rf, newdata = IPQC_test)
rf 
plot(rf)
```


Tuning the mtry. 
```{r,warning = FALSE}
### CV調mtry
library(caret)
#set.seed(100)
mtryGrid <- data.frame(mtry = floor(seq(1, ncol(IPQC_train), length = 10)))
rfTune <- train(passornot ~ Row + obs + ave_rdiffpc, 
                data = IPQC_train,
                method = "rf",
                tuneGrid = mtryGrid,
                ntree = 100,
                importance = TRUE,
                trControl = trainControl(method = "cv",number = 10))
rfTune
plot(rfTune)

```

Calculate the accuracy and sensitivity of testing set.
```{r,warning = FALSE}
### 測試集評估

passornot_test <- IPQC_ROSE$passornot[test]
test_prob <- predict(rf,IPQC_test, type = "prob")
test_label <- predict(rfTune,IPQC_test, type = "raw")
table_test <- table(passornot_test,test_label)

correct_test <- sum(diag(table_test))/sum(table_test)*100
correct_test #測試集資料正確率 69.48529 %  

sensitivity <- table_test[2,2]/sum(table_test[2,])*100
sensitivity #測試集的sensitivity 75.1634%
```


Draw ROC curve
```{r,warning = FALSE}
### ROC
library(pROC)
modelroc_Rrf <- roc(IPQC_test$passornot,test_prob[,"NG"]) # "pass": 1, "NG":2

plot(modelroc_Rrf, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE, auc.polygon.col="skyblue", print.thres=TRUE)


### 變數重要性
rfImp <- varImp(rfTune, scale = FALSE)
rfImp
```

## 2.3 Compare ROC curve
```{r,warning = FALSE}
# compared four ROC curve ####
library(pROC)
library(ggplot2)
roc_tree <- ggroc(list(smote_tree=modelroc_Stree,rose_tree=modelroc_Rtree), legacy.axes = TRUE, aes =c("linetype")) + labs(x = "FPR" , y = "TPR")
roc_tree

roc_rf <- ggroc(list(smote_rf=modelroc_Srf,rose_rf=modelroc_Rrf),legacy.axes = TRUE,aes =c("linetype", "color")) + labs(x = "FPR" , y = "TPR")
roc_rf

roc_rf <- ggroc(list(smote_rf=modelroc_Srf,rose_rf=modelroc_Rrf),legacy.axes = TRUE,aes =c("linetype")) + labs(x = "FPR" , y = "TPR")
roc_rf

roc <- ggroc(list(smote_rf=modelroc_Srf,rose_rf=modelroc_Rrf,smote_tree=modelroc_Stree,rose_tree=modelroc_Rtree), legacy.axes = TRUE,aes =c("linetype")) + labs(x = "FPR" , y = "TPR")
roc

```

# 3. IPQC + FQC data analysis (Part 2)
## 3.1 Filter variables directly by standard deviation
```{r}
load("~/HMD/RDATA/all_w.RData")

#每一批只留完整的資料 
all_w$name
class(all_w$name)
all_w$name <- as.character(all_w$name)
all_onetest <- all_w[-(grep("\\.",all_w$name)),]

#只留下pass的23個obs
all_onetest <- all_onetest[-24,]



```

```{r}
#以整體資料來看，直接取sd較高的變數 
sd <- sapply(all_onetest[-1],sd,na.rm=T)
(quan <- quantile(sd, probs=seq(0,1,0.05))) #取3 作為sd門檻值
all_onetest <- rbind(all_onetest,sapply(all_onetest[-1],sd,na.rm=T)) #將sd計算結果併到dataframe下
all_onetest[24,1] <- "sd" 
filter_sd <- all_onetest[,-which(all_onetest[24,]<3)]
#sort(filter_sd[24,-1])

#col <- sort(all_onetest[24,-1],decreasing = T)[1:20]
#all_onetest <- all_onetest[,c("name",colnames(col))]

#篩選掉sd小於3的變數後，剩下306個變數
```

### 3.1.1 Clustering without PCA
```{r}
#讀取分類(級)表格
library(xlsx)
rank <- read.xlsx("~/HMD/data-20180426/Table_v2.xlsx", encoding="UTF-8", startRow=1, endRow=24, sheetIndex=2)
rank <- rank[,c(4,7)]
rank$name <- as.character(rank$name)
#合併分類表格跟filter_sd (sd那一row不會留下來)
all_rank <- merge(rank,filter_sd,by="name")

#存篩選後資料框
#save(all_rank, file = "./RDATA/sd_rank.RData")

#sd篩完後的資料直接以kmeans 分類
cluster_3 <- kmeans(all_rank[,3:308],3)
all_rank$cluster_3 <- as.factor(cluster_3$cluster)
table(cluster_3$cluster,all_rank$New)
#kmeans跟建立的分類沒有甚麼相似...
```

### 3.1.2 PCA + Clustering
```{r}
#根據306個變數再進行pca 
pcaObject <- prcomp(all_rank[,3:308], center = TRUE, scale. = TRUE)
percentVariance <- pcaObject$sd^2/sum(pcaObject$sd^2)*100
plot(percentVariance, 
     xlab = "Principal Component",
     ylab = "Proportion of Variance Explained ", 
     type = 'b')
```

```{r}
#選十個主成分
cumsum(percentVariance)
plot(cumsum(percentVariance))

#用caret做並繪圖
library(caret)
pp <- preProcess(all_rank[,3:308], method = c("BoxCox","center", "scale", "pca"))
#PCA needed 10 components to capture 95 percent of the variance
transformed <- predict(pp, all_rank[,3:308])


#畫scatter plot matrix ###
##根據PCA分出來的前三項屬性跟我根據HMD的三個分類做散佈圖
PCA <- prcomp(transformed, center = TRUE, scale. = TRUE)
#根據前十個pca去做kmeans
pca_3 <- transformed[,1:10]
pc_kmeans <- kmeans(pca_3,3)
all_rank$pc_kmeans <- as.factor(pc_kmeans$cluster)
table(pc_kmeans$cluster,all_rank$New)
table(pc_kmeans$cluster,all_rank$cluster_3)
```

## 3.2 Fiter variables by standard deviation after grouping dimensions
```{r}
load("~/HMD/RDATA/all_w.RData")

#每一批只留完整的資料 
all_w$name
class(all_w$name)
all_w$name <- as.character(all_w$name)
all_onetest <- all_w[-(grep("\\.",all_w$name)),]

#只留下pass的23個obs
all_onetest <- all_onetest[-24,]

#1. column name 開頭IP_G_II +F_G_II
colnames(all_onetest)
IP_G_II <- grep("IP_G_II",colnames(all_onetest))
F_G_II <- grep("F_G_II",colnames(all_onetest))
G_II <- all_onetest[,c(1,IP_G_II,F_G_II)]
rm(IP_G_II,F_G_II)

#取sd
sd <- sapply(G_II[-1],sd,na.rm=T)
(quan <- quantile(sd, probs=seq(0,1,0.05))) #取8 作為sd門檻值
G_II <- rbind(G_II,sapply(G_II[-1],sd,na.rm=T)) #將sd計算結果併到dataframe下
G_II[24,1] <- "sd" 
G_II <- G_II[,-which(G_II[24,]<8)]
sort(G_II[24,-1])  #剩96個變數

#2. column name 開頭IP_b_II +F_b_II
IP_b_II <- grep("IP_b_II",colnames(all_onetest))
F_b_II <- grep("F_b_II",colnames(all_onetest))
b_II <- all_onetest[,c(1,IP_b_II,F_b_II)]
rm(IP_b_II,F_b_II)

#取sd
sd <- sapply(b_II[-1],sd,na.rm=T)
(quan <- quantile(sd, probs=seq(0,1,0.05))) #取22.5 作為sd門檻值
b_II <- rbind(b_II,sapply(b_II[-1],sd,na.rm=T)) #將sd計算結果併到dataframe下
b_II[24,1] <- "sd" 
b_II <- b_II[,-which(b_II[24,]<22.5)]
sort(b_II[24,-1])  #剩54個變數

#3. column name 開頭IP_G_I +F_G_I 
# 若直接grep"IP_G_I"，"IP_G_II"也會被抓到，所以要用以下語法，抓出"IP_G_I"再屏除"IP_G_II"
IP_G_I <- grep("^(?=.*IP_G_I)(?!.*IP_G_II)", colnames(all_onetest), perl=TRUE)
F_G_I <- grep("^(?=.*F_G_I)(?!.*F_G_II)", colnames(all_onetest), perl=TRUE)
G_I <- all_onetest[,c(1,IP_G_I,F_G_I)]
rm(IP_G_I,F_G_I)

#取sd
sd <- sapply(G_I[-1],sd,na.rm=T)
(quan <- quantile(sd, probs=seq(0,1,0.05))) #取1.5 作為sd門檻值
G_I <- rbind(G_I,sapply(G_I[-1],sd,na.rm=T)) #將sd計算結果併到dataframe下
G_I[24,1] <- "sd" 
G_I <- G_I[,-which(G_I[24,]<1.5)]
sort(G_I[24,-1])  #剩89個變數


#4. column name 開頭IP_b_I +F_b_I
IP_b_I <- grep("^(?=.*IP_b_I)(?!.*IP_b_II)", colnames(all_onetest), perl=TRUE)
F_b_I <- grep("^(?=.*F_b_I)(?!.*F_b_II)", colnames(all_onetest), perl=TRUE)
b_I <- all_onetest[,c(1,IP_b_I,F_b_I)]
rm(IP_b_I,F_b_I)

#取sd
sd <- sapply(b_I[-1],sd,na.rm=T)
(quan <- quantile(sd, probs=seq(0,1,0.05))) #取15.5 作為sd門檻值
b_I <- rbind(b_I,sapply(b_I[-1],sd,na.rm=T)) #將sd計算結果併到dataframe下
b_I[24,1] <- "sd" 
b_I <- b_I[,-which(b_I[24,]<15.5)]
sort(G_I[24,-1])  #剩50個變數

filter <- union(colnames(b_I),colnames(b_II))
filter <- union(filter,colnames(G_I))
filter <- union(filter,colnames(G_II))

#filter為根據四個group篩選sd 取出的289個變數
filter <- all_onetest[,filter]
```

### 3.2.1 Clustering without PCA
```{r}
#加入分級標籤，存RData
library(xlsx)
rank <- read.xlsx("~/HMD/data-20180426/Table_v2.xlsx", encoding="UTF-8", startRow=1, endRow=24, sheetIndex=2)
rank <- rank[,c(4,7)]
rank$name <- as.character(rank$name)
#合併分類表格跟filter_sd (sd那一row不會留下來)
all_rank <- merge(rank,filter,by="name")
# save(all_rank, file = "./RDATA/group_sd_rank.RData")

#sd篩完後的資料直接以kmeans 分類
cluster_3 <- kmeans(filter[,2:290],3)
filter$cluster_3 <- as.factor(cluster_3$cluster)
table(filter$cluster_3,all_rank$New)
```

### 3.2.2 PCA + Clustering
```{r}
#加入分級標籤，存RData
library(xlsx)
rank <- read.xlsx("~/HMD/data-20180426/Table_v2.xlsx", encoding="UTF-8", startRow=1, endRow=24, sheetIndex=2)
rank <- rank[,c(4,7)]
rank$name <- as.character(rank$name)
#合併分類表格跟filter_sd (sd那一row不會留下來)
all_rank <- merge(rank,filter,by="name")
# save(all_rank, file = "./RDATA/group_sd_rank.RData")

#sd篩完後的資料直接以kmeans 分類
cluster_3 <- kmeans(filter[,2:290],3)
filter$cluster_3 <- as.factor(cluster_3$cluster)
table(filter$cluster_3,all_rank$New)



#用caret做PCA並繪圖
library(caret)
pp <- preProcess(all_rank[,3:291], method = c("BoxCox","center", "scale", "pca"))
#PCA needed 10 components to capture 95 percent of the variance
transformed <- predict(pp, all_rank[,3:291])


pcaObject <- prcomp(all_rank[,3:291], center = TRUE, scale. = TRUE)
percentVariance <- pcaObject$sd^2/sum(pcaObject$sd^2)*100
plot(percentVariance, 
     xlab = "Principal Component",
     ylab = "Proportion of Variance Explained ", 
     type = 'b')
#選十個主成分
cumsum(percentVariance)
plot(cumsum(percentVariance))
```



```{r}
#讀取分類(級)表格
library(xlsx)
rank <- read.xlsx("~/HMD/data-20180426/Table_v2.xlsx", encoding="UTF-8", startRow=1, endRow=24, sheetIndex=2)
rankClass <- rank$New
length(rankClass) #23

panelRange <- extendrange(PCA$x[, 1:3])
splom(as.data.frame(PCA$x[, 1:3]), # Scatter Plot Matrices in {lattice}
      groups = rankClass,
      type = c("p","r"), #r是多加迴歸線
      as.table = TRUE,
      auto.key = list(columns = 2),
      prepanel.limits = function(x) panelRange)


#根據前十個pca去做kmeans
pca <- transformed[,1:10]
pc_kmeans <- kmeans(pca,3)
all_rank$pc_kmeans <- as.factor(pc_kmeans$cluster)
table(pc_kmeans$cluster,all_rank$New)
table(pc_kmeans$cluster,all_rank$cluster_3)
```

